Author: Zhenduo Wang

#############################################################################################

Logistic Regression Classifier:
Mean Accuracy:
0.602757767298
p=:0.38831097142449145
r=:0.35438430154008405
f=:0.3451716567922133
Confusion Matrix:
[297, 98, 2, 0]
[103, 160, 4, 0]
[37, 16, 4, 0]
[30, 15, 1, 0]
Feature weights:
	-1.0468	intensifier    
	-0.9022	discourse marker
	-0.8147	adjective/adverb
	-0.8104	preposition    
	-0.5366	polarity       
	-0.3923	politcal       
	-0.3178	punctuation    
	-0.1992	subjectivity   
	-0.1829	named entity   
	-0.0601	stopwords      
	0.0076	laughter       
	0.1116	similarity     
	0.1171	word count     
	0.1478	URLs           
	0.1794	swear words    
	0.3288	celebrity      
	
#############################################################################################

Support Vector Machine Classifier:
Mean Accuracy:
0.544601590451
p=:0.3039860538710627
r=:0.28577156388267816
f=:0.24940065528355665
Confusion Matrix:
[375, 22, 0, 0]
[214, 53, 0, 0]
[55, 2, 0, 0]
[44, 2, 0, 0]

#############################################################################################

Random Forest Classifier:
Mean Accuracy:
0.58345532256
p=:0.28763560023753565
r=:0.31571052557099594
f=:0.29647575937641996
Confusion Matrix:
[314, 79, 4, 0]
[140, 126, 0, 1]
[45, 12, 0, 0]
[42, 4, 0, 0]

#############################################################################################

Voted Classifier:
Mean Accuracy:
0.609015914156
p=:0.3021744274086693
r=:0.32054075981848884
f=:0.299670568014405
Confusion Matrix:
[341, 56, 0, 0]
[154, 113, 0, 0]
[49, 8, 0, 0]
[43, 3, 0, 0]

#############################################################################################
Analysis					
#############################################################################################

We made a feature-classifier based tweet many detection prototype for the first stage. 
In the feature selection part. We have 4 features now (sentiment polarity, subjectivity, 
semantic similarity and discourse marker indicator). These features are measured separately 
and concatenated as one vector to be the input of classifiers. The classifiers takes the 
feature vector as input and output a binary categorical label for each tweet. Now the irony 
detector has 3 embedded classifiers (Logistic regression, Support vector machine and Random 
forest). The accuracies of the classifiers are 0.579, 0.588, 0.547, respectively. We also get 
the precision, recall and F-measure using the official evaluation function. The performances 
of SVM model are generally the best. See the output of our code.

In order to have a taste of the reasons behind the different performance of the classifiers. 
We make confusion matrices for all the classifiers and  do a weight analysis for logistic 
regression model because logistic regression has a linear kernel.  From the confusion matrix, 
random forest and logistic regression classifiers tend to overlook more irony tweets rather 
than marking tweets as irony. But the SVM classifier does not have any tendency according to 
the confusion matrix. Then, we try to understand the importance of the features by the magnitude 
of their weights in logistic regression. They are 0.78, 0.45, -0.03 and 1.92, respectively. This 
means of the 4 features we have now, the semantic similarity is a relative weak feature.

We will use the best one of the classifiers for each step but will still keep evaluating all of 
them with the above methods until the feature measurements are finally developed. Then, we will do 
a final comparison and choose the best one of out of three.


#############################################################################################
#############################################################################################
